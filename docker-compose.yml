version: '3.9'
services:
  redis:
    image: redis
    container_name: "redis_vision"
    ports:
      - "6379:6379"
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping | grep PONG" ]
      interval: 10s
      timeout: 10s
      retries: 10
    profiles:
      - tracking
      - haidetection
  
  redistimeseries:
    image: redislabs/redistimeseries
    container_name: "redistimeseries_vision"
    ports:
      - "6380:6379"
    profiles:
      - tracking
      - haidetection

  grafana:
    build: ./grafana
    container_name: "grafana_vision"
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    profiles:
      - tracking
      - haidetection

  tracker:
    build: ./tracking
    container_name: "tracker_vision"
    command: bash -c "python tracker.py ${MODEL_CONF} --redis ${REDIS_URL}"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1 
              capabilities: [gpu]
    depends_on:
      redis:
        condition: service_healthy
    profiles:
      - tracking
      - haidetection

  producer:
    build: .
    container_name: "producer_vision"
    ports:
      - "5002:5001"
    command: bash -c "python3 producer.py -u ${REDIS_URL} --inputFps ${INPUT_FPS} --outputFps ${OUTPUT_FPS} ${INPUT_FILE} --webcam ${CAMERA} & python3 server.py -u ${REDIS_URL} --trackletLength ${TRACKLET_LENGTH} --score ${SCORE}"
    depends_on:
      redis:
        condition: service_healthy
    profiles:
      - tracking

  producer2:
    build: .
    container_name: "producer2_vision"
    ports:
      - "5002:5001"
    command: bash -c "python3 producer2.py -u ${REDIS_URL} --inputFps ${INPUT_FPS} --outputFps ${OUTPUT_FPS} ${INPUT_FILE} --webcam ${CAMERA} & python3 server2.py -u ${REDIS_URL} --trackletLength ${TRACKLET_LENGTH} --score ${SCORE}"
    depends_on:
      redis:
        condition: service_healthy
    profiles:
      - haidetection

  ona:
    build:
      context: ./cognitivesynergy/ONA
      dockerfile: Dockerfile
    image: ona 
    container_name: ONA
    restart: unless-stopped
    profiles:
      - ona
      - haidetection

  hybridaiobjectdetection:
    depends_on: 
      grafana:
        condition: service_started
      ona:
        condition: service_started
      producer2:
        condition: service_started
      redis:
        condition: service_healthy
      redistimeseries:
        condition: service_started
      tracker:
        condition: service_started
    build: 
      context: ./cognitivesynergy
      dockerfile: Dockerfile
    image: cognitivesynergybase 
    container_name: hybridaiobjectdetection
    volumes:
      - ./cognitivesynergy:/app
      - /var/run/docker.sock:/var/run/docker.sock
    command: python3 main_detection.py
    stdin_open: true
    tty: true
    profiles:
      - haidetection

  hybridaiobjecttracking:
    depends_on: 
      - ona
    build: 
      context: .
      dockerfile: Dockerfile
    image: cognitivesynergybase 
    container_name: hybridaiobjecttracking
    volumes:
      - .:/app
    command: python main_tracking.py
    profiles:
      - haitracking

  hybridaistreamingtext:
    depends_on: 
      - ona
    build: .
    volumes:
      - .:/app
    command: python main_text.py
    profiles:
      - haitext

  hybridainetworking:
    depends_on: 
      - ona
    build: .
    volumes:
      - .:/app
    command: python main_networking.py
    profiles:
      - hainetworking

volumes:
  grafana-data:
    name: grafana-data
